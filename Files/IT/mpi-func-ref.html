<html>

<head>
<title>Параллельная обработка данных - лекция 5. Message Passing Interface (MPI)</title>
<LINK href="default.css" rel="stylesheet" type="text/css">
</head>

<BODY BGCOLOR="#F0FFFF" onLoad='if (parent.index!=null) parent.index.SwitchOn(7);'>
<TABLE width="100%" cellspacing=0 cellpadding=3 border=0><TR bgColor="#800000">
<TD bgColor="#008080"><FONT color="#FFFFFF" ><B>&nbsp;ИНФОРМАЦИЯ&nbsp;</FONT>
<TD bgColor="#008080" align=Right><A HREF="/parallel/" target=_top><IMG src="/images/pc4.gif" border=0><IMG src="/images/pcHome.gif" border=0></A>
</TABLE>
<P class=copyright>&copy; <em>Воеводин Вл.В.</em><BR>
<A HREF="index.html">Курс лекций</A><BR>"Параллельная обработка данных"

<H1>Лекция 5. Технологии параллельного программирования.<BR> Message Passing Interface (MPI)</H1>
<P>План лекции:
<UL>
<LI><A HREF="#p1">MPI. Терминология и обозначения</A>
<LI><A HREF="#p2">Общие процедуры MPI</A>
<LI><A HREF="#p3">Прием/передача сообщений между отдельными процессами</A>
<LI><A HREF="#p4">Объединение запросов на взаимодействие</A>
<LI><A HREF="#p5">Совмещенные прием/передача сообщений</A>
<LI><A HREF="#p6">Коллективные взаимодействия процессов</A>
<LI><A HREF="#p7">Синхронизация процессов</A>
<LI><A HREF="#p8">Работа с группами процессов</A>
<LI><A HREF="#p9">Предопределенные константы</A>
<LI><A HREF="examples.html">Примеры MPI-программ</A>
</UL>
<HR>

<A NAME="p1"></A>
<H3>MPI. Терминология и обозначения</H3>

<P><em>MPI - message passing interface</em> - библиотека функций, предназначенная
для поддержки работы параллельных процессов в терминах передачи сообщений.

<P><em>Номер процесса</em> - целое неотрицательное число,
являющееся уникальным
атрибутом каждого процесса. 

<P><em>Атрибуты сообщения</em> - номер процесса-отправителя, номер процесса-получателя
и идентификатор сообщения. Для них заведена структура <em>MPI_Status</em>,
содержащая три поля: <em>MPI_Source</em> (номер процесса отправителя), <em>MPI_Tag</em>
(идентификатор сообщения), <em>MPI_Error</em> (код ошибки); могут быть и
добавочные поля. 

<P><em>Идентификатор сообщения (msgtag)</em> - атрибут сообщения, являющийся
целым неотрицательным числом, лежащим в диапазоне от 0 до 32767. <BR>
Процессы объединяются в <em>группы</em>, могут быть вложенные группы. Внутри
группы все процессы перенумерованы. С каждой группой ассоциирован свой
<em>коммуникатор</em>. Поэтому при осуществлении пересылки необходимо указать
идентификатор группы, внутри которой производится эта пересылка. Все процессы
содержатся в группе с предопределенным идентификатором <em>MPI_COMM_WORLD</em>.

<HR>
<P>При описании процедур MPI будем пользоваться
словом OUT для обозначения "выходных" параметров,
т.е. таких параметров, через которые процедура возвращает
результаты.
<HR>
<A NAME="p2"></A>
<H3>Общие процедуры MPI</H3>

<P><strong>int MPI_Init( int* argc, char*** argv)</strong>

<P><em>MPI_Init</em> - инициализация параллельной части приложения. Реальная
инициализация для каждого приложения выполняется не более одного раза,
а если MPI уже был инициализирован, то никакие действия не выполняются
и происходит немедленный возврат из подпрограммы. Все оставшиеся MPI-процедуры
могут быть вызваны только после вызова <em>MPI_Init</em>. 

<P>Возвращает: в случае успешного выполнения - <em>MPI_SUCCESS</em>, иначе
- код ошибки. (То же самое возвращают и все остальные функции, рассматриваемые
в данном руководстве.) 
<HR>
<P><strong>int MPI_Finalize( void )</strong> 
<P><em>MPI_Finalize</em> - завершение параллельной части приложения. Все последующие
обращения к любым MPI-процедурам, в том числе к <em>MPI_Init</em>, запрещены.
К моменту вызова <em>MPI_Finalize</em> некоторым процессом все действия,
требующие его участия в обмене сообщениями, должны быть завершены. <BR>
Сложный тип аргументов <em>MPI_Init</em> предусмотрен для того, чтобы передавать
всем процессам аргументы <em>main</em>:</P>

<PRE>
int main(int argc, char** argv)
{
      MPI_Init(&amp;argc, &amp;argv);
          ...
      MPI_Finalize();
}
</PRE>
<HR>
<P><strong>int MPI_Comm_size( MPI_Comm comm, int* size)</strong> 

<P>Определение общего числа параллельных процессов в группе <em>comm</em>.
<UL>
<LI><em>comm</em> - идентификатор группы 
<LI>OUT <em>size</em> - размер группы 
</UL>

<HR>

<P><strong>int MPI_Comm_rank( MPI_Comm comm, int* rank)</strong> 

<P>Определение номера процесса в группе <em>comm</em>. Значение, возвращаемое
по адресу <em>&amp;rank</em>, лежит в диапазоне от 0 до <em>size_of_group-1</em>.

<UL>
<LI><em>comm</em> - идентификатор группы 
<LI>OUT <em>rank</em> - номер вызывающего процесса в группе <em>comm</em> 
</UL>

<HR>

<P><strong>double MPI_Wtime(void)</strong> 
<P>Функция возвращает астрономическое время в секундах (вещественное число),
прошедшее с некоторого момента в прошлом. Гарантируется, что этот момент
не будет изменен за время существования процесса. 

<HR>
<A NAME="p3"></A>
<H3>Прием/передача сообщений между отдельными процессами</H3>
<H4>Прием/передача сообщений с блокировкой</H4>


<P><strong>int MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest,
int msgtag, MPI_Comm comm) </strong>

<UL>
<LI><em>buf</em> - адрес начала буфера посылки сообщения
<LI><em>count</em> - число передаваемых элементов в сообщении
<LI><em>datatype</em> - тип передаваемых элементов
<LI><em>dest</em> - номер процесса-получателя
<LI><em>msgtag</em> - идентификатор сообщения
<LI><em>comm</em> - идентификатор группы
</UL>

<P>Блокирующая посылка сообщения с идентификатором <em>msgtag</em>, состоящего
из <em>count</em> элементов типа <em>datatype</em>, процессу с номером <em>dest</em>.
Все элементы сообщения расположены подряд в буфере <em>buf</em>. Значение
<em>count</em> может быть нулем. Тип передаваемых элементов <em>datatype</em>
должен указываться с помощью предопределенных констант типа. Разрешается
передавать сообщение самому себе. 
<P>Блокировка гарантирует корректность повторного использования всех параметров
после возврата из подпрограммы. Выбор способа осуществления этой гарантии:
копирование в промежуточный буфер или непосредственная передача процессу
<em>dest</em>, остается за MPI. Следует специально отметить, что возврат
из подпрограммы <em>MPI_Send</em> не означает ни того, что сообщение уже
передано процессу <em>dest</em>, ни того, что сообщение покинуло процессорный
элемент, на котором выполняется процесс, выполнивший <em>MPI_Send</em>. 

<HR>
<P><strong>int MPI_Recv(void* buf, int count, MPI_Datatype datatype, int source,
int msgtag, MPI_Comm comm, MPI_Status *status)</strong>

<UL>
<LI>OUT <em>buf</em> - адрес начала буфера приема сообщения 
<LI><em>count</em> - максимальное число элементов в принимаемом сообщении
<LI><em>datatype</em> - тип элементов принимаемого сообщения
<LI><em>source</em> - номер процесса-отправителя
<LI><em>msgtag</em> - идентификатор принимаемого сообщения
<LI><em>comm</em> - идентификатор группы
<LI>OUT <em>status</em> - параметры принятого сообщения
</UL>

<P>Прием сообщения с идентификатором <em>msgtag</em> от процесса <em>source</em>
с блокировкой. Число элементов в принимаемом сообщении не должно превосходить
значения <em>count</em>. Если число принятых элементов меньше значения <em>count</em>,
то гарантируется, что в буфере <em>buf</em> изменятся только элементы, соответствующие
элементам принятого сообщения. Если нужно узнать точное число элементов
в сообщении, то можно воспользоваться подпрограммой <em>MPI_Probe</em>. 
<P>Блокировка гарантирует, что после возврата из подпрограммы все элементы
сообщения приняты и расположены в буфере <em>buf</em>. 
<P>В качестве номера процесса-отправителя можно указать предопределенную константу
<em>MPI_ANY_SOURCE</em> - признак того, что подходит сообщение от любого
процесса. В качестве идентификатора принимаемого сообщения можно указать
константу <em>MPI_ANY_TAG</em> - признак того, что подходит сообщение с любым
идентификатором.
<P>Если процесс посылает два сообщения другому процессу и оба эти сообщения
соответствуют одному и тому же вызову <em>MPI_Recv</em>, то первым будет
принято то сообщение, которое было отправлено раньше.
<HR>

<P><strong>int MPI_Get_count( MPI_Status *status, MPI_Datatype datatype, int
*count)</strong> 

<UL>
<LI><em>status</em> - параметры принятого сообщения
<LI><em>datatype</em> - тип элементов принятого сообщения
<LI>OUT <em>count</em> - число элементов сообщения
</UL>

<P>По значению параметра <em>status</em> данная подпрограмма определяет число
уже принятых (после обращения к <em>MPI_Recv</em>) или принимаемых (после
обращения к <em>MPI_Probe</em> или <em>MPI_Iprobe</em>) элементов сообщения
типа <em>datatype</em>. 
<HR>
<P><strong>int MPI_Probe( int source, int msgtag, MPI_Comm comm, MPI_Status
*status)</strong> 

<UL>
<LI><em>source</em> - номер процесса-отправителя или <em>MPI_ANY_SOURCE</em>
<LI><em>msgtag</em> - идентификатор ожидаемого сообщения или <em>MPI_ANY_TAG</em>
<LI><em>comm</em> - идентификатор группы <BR>
<LI>OUT <em>status</em> - параметры обнаруженного сообщения <BR>
</UL>

<P>Получение информации о структуре ожидаемого сообщения с блокировкой.
Возврата из подпрограммы не произойдет до тех пор, пока сообщение с подходящим
идентификатором и номером процесса-отправителя не будет доступно для получения.
Атрибуты доступного сообщения можно определить обычным образом с помощью
параметра <em>status</em>. Следует обратить внимание, что подпрограмма определяет
только факт прихода сообщения, но реально его не принимает. 
<HR>
<H4>Прием/передача сообщений без блокировки</H4>

<P><strong>int MPI_Isend(void *buf, int count, MPI_Datatype datatype, int dest, 
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

<UL>
<LI><em>buf</em> - адрес начала буфера посылки сообщения 
<LI><em>count</em> - число передаваемых элементов в сообщении 
<LI><em>datatype</em> - тип передаваемых элементов
<LI><em>dest</em> - номер процесса-получателя 
<LI><em>msgtag</em> - идентификатор сообщения
<LI><em>comm</em> - идентификатор группы
<LI>OUT <em>request</em> - идентификатор асинхронной передачи
</UL>

<P>Передача сообщения, аналогичная <em>MPI_Send</em>, однако возврат из подпрограммы
происходит сразу после инициализации процесса передачи без ожидания обработки
всего сообщения, находящегося в буфере <em>buf</em>. Это означает, что нельзя
повторно использовать данный буфер для других целей без получения дополнительной
информации о завершении данной посылки. Окончание процесса передачи (т.е.
того момента, когда можно переиспользовать буфер <em>buf</em> без опасения
испортить передаваемое сообщение) можно определить с помощью параметра
<em>request</em> и процедур <em>MPI_Wait</em> и <em>MPI_Test</em>. <BR>
Сообщение, отправленное любой из процедур <em>MPI_Send</em> и <em>MPI_Isend</em>,
может быть принято любой из процедур <em>MPI_Recv</em> и <em>MPI_Irecv</em>.

<HR>

<P><strong>int MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source,
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

<UL>
<LI>OUT <em>buf</em> - адрес начала буфера приема сообщения 
<LI><em>count</em> - максимальное число элементов в принимаемом сообщении 
<LI><em>datatype</em> - тип элементов принимаемого сообщения 
<LI><em>source</em> - номер процесса-отправителя
<LI><em>msgtag</em> - идентификатор принимаемого сообщения 
<LI><em>comm</em> - идентификатор группы 
<LI>OUT <em>request</em> - идентификатор асинхронного приема сообщения 
</UL>

<P>Прием сообщения, аналогичный <em>MPI_Recv</em>, однако возврат из подпрограммы
происходит сразу после инициализации процесса приема без ожидания получения
сообщения в буфере <em>buf</em>. Окончание процесса приема можно определить
с помощью параметра <em>request</em> и процедур <em>MPI_Wait</em> и <em>MPI_Test</em>.

<HR>

<P><strong>int MPI_Wait( MPI_Request *request, MPI_Status *status)</strong>

<UL>
<LI><em>request</em> - идентификатор асинхронного приема или передачи 
<LI>OUT <em>status</em> - параметры сообщения 
</UL>

<P>Ожидание завершения асинхронных процедур <em>MPI_Isend</em> или <em>MPI_Irecv</em>,
ассоциированных с идентификатором <em>request</em>. В случае приема, атрибуты
и длину полученного сообщения можно определить обычным образом с помощью
параметра <em>status</em>. 
<HR>
<P><strong>int MPI_Waitall( int count, MPI_Request *requests, MPI_Status *statuses)
</strong>

<UL>
<LI><em>count</em> - число идентификаторов 
<LI><em>requests</em> - массив идентификаторов асинхронного приема или передачи
<LI>OUT <em>statuses</em> - параметры сообщений
</UL>

<P>Выполнение процесса блокируется до тех пор, пока все операции обмена,
ассоциированные с указанными идентификаторами, не будут завершены. Если
во время одной или нескольких операций обмена возникли ошибки, то поле
ошибки в элементах массива <em>statuses</em> будет установлено в соответствующее
значение. 

<HR>

<P><strong>int MPI_Waitany( 
int count, MPI_Request *requests, int *index, 
MPI_Status *status) </strong>

<UL>
<LI><em>count</em> - число идентификаторов 
<LI><em>requests</em> - массив идентификаторов асинхронного приема или передачи
<LI>OUT <em>index</em> - номер завершенной операции обмена 
<LI>OUT <em>status</em> - параметры сообщений 
</UL>

<P>Выполнение процесса блокируется до тех пор, пока какая-либо операция
обмена, ассоциированная с указанными идентификаторами, не будет завершена.
Если несколько операций могут быть завершены, то случайным образом выбирается
одна из них. Параметр <em>index</em> содержит номер элемента в массиве <em>requests</em>,
содержащего идентификатор завершенной операции. 

<HR>
<P><strong>int MPI_Waitsome( 
int incount, MPI_Request *requests, int *outcount, 
int *indexes, MPI_Status *statuses)</strong>
<UL>
<LI><em>incount</em> - число идентификаторов 
<LI><em>requests</em> - массив идентификаторов асинхронного приема или передачи
<LI>OUT <em>outcount</em> - число идентификаторов завершившихся операций обмена
<LI>OUT <em>indexes</em> - массив номеров завершившихся операции обмена 
<LI>OUT <em>statuses</em> - параметры завершившихся сообщений
</UL>

<P>Выполнение процесса блокируется до тех пор, пока по крайней мере одна
из операций обмена, ассоциированных с указанными идентификаторами, не будет
завершена. Параметр <em>outcount</em> содержит число завершенных операций,
а первые <em>outcount</em> элементов массива <em>indexes</em> содержат номера
элементов массива <em>requests</em> с их идентификаторами. Первые <em>outcount</em>
элементов массива <em>statuses</em> содержат параметры завершенных операций.

<HR>
<P><strong>int MPI_Test( MPI_Request *request, int *flag, MPI_Status *status)
</strong>

<UL>
<LI><em>request</em> - идентификатор асинхронного приема или передачи
<LI>OUT <em>flag</em> - признак завершенности операции обмена 
<LI>OUT <em>status</em> - параметры сообщения
</UL>

<P>Проверка завершенности асинхронных процедур <em>MPI_Isend</em> или <em>MPI_Irecv</em>,
ассоциированных с идентификатором <em>request</em>. В параметре <em>flag</em>
возвращает значение 1, если соответствующая операция завершена, и значение
0 в противном случае. Если завершена процедура приема, то атрибуты и длину
полученного сообщения можно определить обычным образом с помощью параметра
<em>status</em>. 

<HR>

<P><strong>int MPI_Testall( 
int count, MPI_Request *requests, int *flag, 
MPI_Status *statuses)</strong>

<UL>
<LI><em>count</em> - число идентификаторов <BR>
<LI><em>requests</em> - массив идентификаторов асинхронного приема или передачи
<LI>OUT <em>flag</em> - признак завершенности операций обмена <BR>
<LI>OUT <em>statuses</em> - параметры сообщений <BR>
</UL>

<P>В параметре <em>flag</em> возвращает значение <em>1</em>, если все операции,
ассоциированные с указанными идентификаторами, завершены (с указанием параметров
сообщений в массиве <em>statuses</em>). В противном случае возвращается <em>0</em>,
а элементы массива <em>statuses</em> неопределены. 

<HR>

<P><strong>int MPI_Testany(int count, MPI_Request *requests, int *index, 
int *flag, MPI_Status *status)</strong>

<UL>
<LI><em>count</em> - число идентификаторов 
<LI><em>requests</em> - массив идентификаторов асинхронного приема или передачи
<LI>OUT <em>index</em> - номер завершенной операции обмена 
<LI>OUT <em>flag</em> - признак завершенности операции обмена 
<LI>OUT <em>status</em> - параметры сообщения 
</UL>

<P>Если к моменту вызова подпрограммы хотя бы одна из операций обмена завершилась,
то в параметре <em>flag</em> возвращается значение <em>1</em>, <em>index</em>
содержит номер соответствующего элемента в массиве <em>requests</em>, а <em>status</em>
- параметры сообщения. 
<HR>

<P><strong>int MPI_Testsome( 
int incount, MPI_Request *requests, int *outcount, 
int *indexes, MPI_Status *statuses)</strong>

<UL>
<LI><em>incount</em> - число идентификаторов 
<LI><em>requests</em> - массив идентификаторов асинхронного приема или передачи
<LI>OUT <em>outcount</em> - число идентификаторов завершившихся операций обмена
<LI>OUT <em>indexes</em> - массив номеров завершившихся операции обмена
<LI>OUT <em>statuses</em> - параметры завершившихся операций <BR>
</UL>

<P>Данная подпрограмма работает так же, как и <em>MPI_Waitsome</em>, 
за исключением того, что возврат происходит немедленно. Если ни одна из указанных операций
не завершилась, то значение <em>outcount</em> будет равно нулю. 
<HR>

<P><strong>int MPI_Iprobe( 
int source, int msgtag, MPI_Comm comm, int *flag, 
MPI_Status *status)</strong>

<UL>
<LI><em>source</em> - номер процесса-отправителя или <em>MPI_ANY_SOURCE</em>
<LI><em>msgtag</em> - идентификатор ожидаемого сообщения или <em>MPI_ANY_TAG</em>
<LI><em>comm</em> - идентификатор группы
<LI>OUT <em>flag</em> - признак завершенности операции обмена 
<LI>OUT <em>status</em> - параметры обнаруженного сообщения 
</UL>

<P>Получение информации о поступлении и структуре ожидаемого сообщения
без блокировки. В параметре <em>flag</em> возвращает значение <em>1</em>, если
сообщение с подходящими атрибутами уже может быть принято (в этом случае
ее действие полностью аналогично <em>MPI_Probe</em>), и значение <em>0</em>,
если сообщения с указанными атрибутами еще нет. 

<HR>
<A NAME="p4"></A>
<H3>Объединение запросов на взаимодействие</H3>

<P>Процедуры данной группы позволяют снизить накладные расходы, возникающие
в рамках одного процессора при обработке приема/передачи и перемещении
необходимой информации между процессом и сетевым контроллером. Несколько
запросов на прием и/или передачу могут объединяться вместе для того, чтобы
далее их можно было бы запустить одной командой. Способ приема сообщения
никак не зависит от способа его посылки: сообщение, отправленное с помощью
объединения запросов либо обычным способом, может быть принято как обычным
способом, так и с помощью объединения запросов. 


<P><strong>int MPI_Send_init( 
void *buf, int count, MPI_Datatype datatype, int dest, 
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

<UL>
<LI><em>buf</em> - адрес начала буфера посылки сообщения
<LI><em>count</em> - число передаваемых элементов в сообщении
<LI><em>datatype</em> - тип передаваемых элементов
<LI><em>dest</em> - номер процесса-получателя
<LI><em>msgtag</em> - идентификатор сообщения 
<LI><em>comm</em> - идентификатор группы
<LI>OUT <em>request</em> - идентификатор асинхронной передачи 
</UL>

<P>Формирование запроса на выполнение пересылки данных. Все параметры точно
такие же, как и у подпрограммы <em>MPI_Isend</em>, однако в отличие от нее
пересылка не начинается до вызова подпрограммы <em>MPI_Startall</em>. 

<HR>
<P><strong>int MPI_Recv_init( 
void *buf, int count, MPI_Datatype datatype, int source, 
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

<UL>
<LI>OUT <em>buf</em> - адрес начала буфера приема сообщения
<LI><em>count</em> - число принимаемых элементов в сообщении 
<LI><em>datatype</em> - тип принимаемых элементов
<LI><em>source</em> - номер процесса-отправителя
<LI><em>msgtag</em> - идентификатор сообщения
<LI><em>comm</em> - идентификатор группы
<LI>OUT <em>request</em> - идентификатор асинхронного приема 
</UL>

<P>Формирование запроса на выполнение приема данных. Все параметры точно
такие же, как и у подпрограммы <em>MPI_Irecv</em>, однако в отличие от
нее реальный прием не начинается до вызова подпрограммы <em>MPI_Startall</em>.

<HR>
<P><strong>MPI_Startall( int count, MPI_Request *requests) </strong>

<UL>
<LI><em>count</em> - число запросов на взаимодействие 
<LI>OUT <em>requests</em> - массив идентификаторов приема/передачи 
</UL>

<P>Запуск всех отложенных взаимодействий, ассоциированных вызовами подпрограмм
<em>MPI_Send_init</em> и <em>MPI_Recv_init</em> с элементами массива запросов
<em>requests</em>. Все взаимодействия запускаются в режиме без блокировки,
а их завершение можно определить обычным образом с помощью процедур <em>MPI_Wait</em>
и <em>MPI_Test</em>. 
<HR>
<A NAME="p5"></A>
<H3>Совмещенные прием/передача сообщений</H3>

<P><strong>int MPI_Sendrecv( 
void *sbuf, int scount, MPI_Datatype stype, 
int dest, int stag, void *rbuf, int rcount, 
MPI_Datatype rtype, int source, MPI_Datatype rtag, 
MPI_Comm comm, MPI_Status *status)</strong>

<UL>
<LI><em>sbuf</em> - адрес начала буфера посылки сообщения
<LI><em>scount</em> - число передаваемых элементов в сообщении 
<LI><em>stype</em> - тип передаваемых элементов
<LI><em>dest</em> - номер процесса-получателя
<LI><em>stag</em> - идентификатор посылаемого сообщения 
<LI>OUT <em>rbuf</em> - адрес начала буфера приема сообщения
<LI><em>rcount</em> - число принимаемых элементов сообщения 
<LI><em>rtype</em> - тип принимаемых элементов
<LI><em>source</em> - номер процесса-отправителя
<LI><em>rtag</em> - идентификатор принимаемого сообщения
<LI><em>comm</em> - идентификатор группы 
<LI>OUT <em>status</em> - параметры принятого сообщения 
</UL>

<P>Данная операция объединяет в едином запросе посылку и прием сообщений.
Принимающий и отправляющий процессы могут являться одним и тем же процессом.
Сообщение, отправленное операцией <em>MPI_Sendrecv</em>, может быть принято
обычным образом, и точно также операция <em>MPI_Sendrecv</em> может принять
сообщение, отправленное обычной операцией <em>MPI_Send</em>. Буфера приема
и посылки обязательно должны быть различными. 

<HR>
<A NAME="p6"></A>
<H3>Коллективные взаимодействия процессов</H3>

<P>В операциях коллективного взаимодействия процессов участвуют все процессы
коммуникатора. Соответствующая процедура должна быть вызвана каждым процессом,
быть может, со своим набором параметров. Возврат из процедуры коллективного
взаимодействия может произойти в тот момент, когда участие процесса в данной
операции уже закончено. Как и для блокирующих процедур, возврат означает
то, что разрешен свободный доступ к буферу приема или посылки, но не означает
ни того, что операция завершена другими процессами, ни даже того, что она
ими начата (если это возможно по смыслу операции). 

<P><strong>int MPI_Bcast(void *buf, int count, MPI_Datatype datatype,
int source, MPI_Comm comm)</strong> 
<UL>
<LI>OUT <em>buf</em> - адрес начала буфера посылки сообщения
<LI><em>count</em> - число передаваемых элементов в сообщении 
<LI><em>datatype</em> - тип передаваемых элементов
<LI><em>source</em> - номер рассылающего процесса 
<LI><em>comm</em> - идентификатор группы 
</UL>

<P>Рассылка сообщения от процесса <em>source</em> всем процессам, включая
рассылающий процесс. При возврате из процедуры содержимое буфера <em>buf</em>
процесса <em>source</em> будет скопировано в локальный буфер процесса. Значения
параметров <em>count</em>, <em>datatype</em> и <em>source</em> должны быть одинаковыми
у всех процессов. 

<HR>
<P><strong>int MPI_Gather( 
void *sbuf, int scount, MPI_Datatype stype, 
void *rbuf, int rcount, MPI_Datatype rtype, 
int dest, MPI_Comm comm)</strong>

<UL>
<LI><em>sbuf</em> - адрес начала буфера посылки 
<LI><em>scount</em> - число элементов в посылаемом сообщении 
<LI><em>stype</em> - тип элементов отсылаемого сообщения
<LI>OUT <em>rbuf</em> - адрес начала буфера сборки данных 
<LI><em>rcount</em> - число элементов в принимаемом сообщении 
<LI><em>rtype</em> - тип элементов принимаемого сообщения
<LI><em>dest</em> - номер процесса, на котором происходит сборка данных
<LI><em>comm</em> - идентификатор группы 
<LI>OUT <em>ierror</em> - код ошибки 

</UL>

<P>Сборка данных со всех процессов в буфере <em>rbuf</em> процесса <em>dest</em>.
Каждый процесс, включая <em>dest</em>, посылает содержимое своего буфера
<em>sbuf</em> процессу <em>dest</em>. Собирающий процесс сохраняет данные в
буфере <em>rbuf</em>, располагая их в порядке возрастания номеров процессов.
Параметр <em>rbuf</em> имеет значение только на собирающем процессе и на
остальных игнорируется, значения параметров <em>count</em>, <em>datatype</em>
и <em>dest</em> должны быть одинаковыми у всех процессов. 

<HR>

<P><strong>int MPI_Allreduce( 
void *sbuf, void *rbuf, int count, 
MPI_Datatype datatype, MPI_Op op, MPI_Comm comm) 
</strong>
<UL>
<LI><em>sbuf</em> - адрес начала буфера для аргументов 
<LI>OUT <em>rbuf</em> - адрес начала буфера для результата 
<LI><em>count</em> - число аргументов у каждого процесса 
<LI><em>datatype</em> - тип аргументов 
<LI><em>op</em> - идентификатор глобальной операции 
<LI><em>comm</em> - идентификатор группы 
</UL>

<P>Выполнение <em>count</em> глобальных операций <em>op</em> с возвратом <em>count</em>
результатов во всех процессах в буфере <em>rbuf</em>. Операция выполняется
независимо над соответствующими аргументами всех процессов. Значения параметров
<em>count</em> и <em>datatype</em> у всех процессов должны быть одинаковыми.
Из соображений эффективности реализации предполагается, что операция <em>op</em>
обладает свойствами ассоциативности и коммутативности. 
<HR>

<P><strong>int MPI_Reduce( 
void *sbuf, void *rbuf, int count, 
MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm) 
</strong>

<UL>
<LI><em>sbuf</em> - адрес начала буфера для аргументов 
<LI>OUT <em>rbuf</em> - адрес начала буфера для результата
<LI><em>count</em> - число аргументов у каждого процесса 
<LI><em>datatype</em> - тип аргументов 
<LI><em>op</em> - идентификатор глобальной операции 
<LI><em>root</em> - процесс-получатель результата 
<LI><em>comm</em> - идентификатор группы 
</UL>

<P>Функция аналогична предыдущей, но результат будет записан в буфер <em>rbuf</em>
только у процесса <em>root</em>. 

<HR>
<A NAME="p7"></A>
<H3>Синхронизация процессов</H3>

<P><strong>int MPI_Barrier( MPI_Comm comm) </strong>

<UL>
<LI><em>comm</em> - идентификатор группы 
</UL>

<P>Блокирует работу процессов, вызвавших данную процедуру, до тех пор,
пока все оставшиеся процессы группы <em>comm</em> также не выполнят эту процедуру.
<HR>
<A NAME="p8"></A>
<H3>Работа с группами процессов</H3>

<P><strong>int MPI_Comm_split( MPI_Comm comm,
int color, int key, MPI_Comm *newcomm)
</strong>

<UL>
<LI><em>comm</em> - идентификатор группы 
<LI><em>color</em> - признак разделения на группы 
<LI><em>key</em> - параметр, определяющий нумерацию в новых группах 
<LI>OUT <em>newcomm</em> - идентификатор новой группы 
</UL>
 
<P>Данная процедура разбивает все множество процессов, входящих в группу
<em>comm</em>, на непересекающиеся подгруппы - одну подгруппу на каждое значение
параметра <em>color</em> (неотрицательное число). Каждая новая подгруппа
содержит все процессы одного цвета. Если в качестве <em>color</em> указано
значение <em>MPI_UNDEFINED</em>, то в <em>newcomm</em> будет возвращено значение
<em>MPI_COMM_NULL</em>. 

<HR>
<P><strong>int MPI_Comm_free( MPI_Comm comm) </strong>

<UL>
<LI>OUT <em>comm</em> - идентификатор группы 

</UL>

<P>Уничтожает группу, ассоциированную с идентификатором <em>comm</em>, который
после возвращения устанавливается в <em>MPI_COMM_NULL</em>. 

<HR>
<A NAME="p9"></A>
<H3>Предопределенные константы</H3>

<H4>Предопределенные константы типа элементов сообщений</H4>

<CENTER><TABLE BORDER=1>
<TR>
<TD>

<TR BGCOLOR="#CBD1DA">
<TD>Константы MPI 
<TD>Тип в C 
<TR>
<TD>


<TR>
<TD><em>MPI_CHAR </em>
<TD>signed char 

<TR>
<TD><em>MPI_SHORT </em>
<TD>signed int 

<TR>
<TD><em>MPI_INT </em>
<TD>signed int 

<TR>
<TD><em>MPI_LONG </em>
<TD>signed long int 

<TR>
<TD><em>MPI_UNSIGNED_CHAR </em>
<TD>unsigned char 

<TR>
<TD><em>MPI_UNSIGNED_SHORT </em>
<TD>unsigned int 

<TR>
<TD><em>MPI_UNSIGNED </em>
<TD>unsigned int 

<TR>
<TD><em>MPI_UNSIGNED_LONG </em>
<TD>unsigned long int 

<TR>
<TD><em>MPI_FLOAT </em>
<TD>float 

<TR>
<TD><em>MPI_DOUBLE </em>
<TD>double 

<TR>
<TD><em>MPI_LONG_DOUBLE </em>
<TD>long double 

</TABLE></CENTER>

<HR>
<P><strong>Другие предопределенные типы </strong>

<P><em>MPI_Status</em> - структура; атрибуты сообщений; содержит три обязательных
поля: 
<UL>
<LI><em>MPI_Source</em> (номер процесса отправителя) 
<LI><em>MPI_Tag</em> (идентификатор сообщения) 
<LI><em>MPI_Error</em> (код ошибки) 
</UL>
<HR>
<P><em>MPI_Request</em> - системный тип; идентификатор операции посылки-приема
сообщения 
<HR>
<P><em>MPI_Comm</em> - системный тип; идентификатор группы (коммуникатора)
<UL>
<LI><P><em>MPI_COMM_WORLD</em>  - зарезервированный идентификатор группы, состоящей их всех процессов
приложения
</UL>
<HR>
<P><strong>Константы-пустышки</strong>
<UL>
<LI><em>MPI_COMM_NULL</em> 
<LI><em>MPI_DATATYPE_NULL</em> 
<LI><em>MPI_REQUEST_NULL</em> 
</UL>
<P><B>Константа неопределенного значения</B> 
<UL>
<LI><em>MPI_UNDEFINED</em> 
</UL>
<HR>
<P><strong>Глобальные операции</strong> 
<P><em>MPI_MAX</em> 
<P><em>MPI_MIN</em> 
<P><em>MPI_SUM</em> 
<P><em>MPI_PROD</em> 
<HR>
<P><strong>Любой процесс/идентификатор</strong> 
<P><em>MPI_ANY_SOURCE</em> 
<P><em>MPI_ANY_TAG</em> 
<HR>
<P><strong>Код успешного завершения процедуры</strong> 
<P><em>MPI_SUCCESS</em> 
<hr>

<TABLE BORDER="1" WIDTH="90%" align="center" cellspacing="5" bgcolor="#F0FFFF">
<TR>
<TD align="center" bgColor="#FFFFFF">
<img SRC="/images/icons/cross.gif" align="top">
<A HREF="examples.html">Примеры MPI-программ</A>

<TD align="center" bgColor="#FFFFFF">
<img SRC="/images/icons/cross.gif" align="top">
<A HREF="/parallel/tech/tech_dev/mpi.html">Страница MPI</A>

<TD align="center" bgColor="#FFFFFF">
<img SRC="/images/icons/cross.gif" align="top">
<A HREF="index.html">
Содержание курса</A>

<TD align="center" bgColor="#FFFFFF">
<img SRC="/images/icons/cross.gif" align="top">
<A HREF="lec6.html">Следующая лекция. Технология программирования OpenMP.</A>
</TR>
</TABLE>

<hr>
<p class=copyright align=right> &copy; Лаборатория Параллельных Информационных Технологий, НИВЦ МГУ
<!--- BEGIN code for counters ---><img src="http://counter.rambler.ru/top100.cnt?18502" alt="Rambler's Top100" width=1 height=1 border=0><!--- END code for counters --->
</body>
</html>
